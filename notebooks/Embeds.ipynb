{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 85256,
     "status": "ok",
     "timestamp": 1750992039756,
     "user": {
      "displayName": "Alan F",
      "userId": "07540241737049634292"
     },
     "user_tz": -480
    },
    "id": "Sydp7DA5L0UB",
    "outputId": "f193a74a-a4e3-43af-87e6-0a647b4c6bd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'psychology-tutor-engine'...\n",
      "remote: Enumerating objects: 40, done.\u001b[K\n",
      "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
      "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
      "remote: Total 40 (delta 7), reused 38 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (40/40), 212.25 KiB | 1.04 MiB/s, done.\n",
      "Resolving deltas: 100% (7/7), done.\n",
      "/content/psychology-tutor-engine\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (18.1.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.52.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.6.15)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
      "\n",
      "\n",
      "✅ Repository cloned and essential libraries installed.\n",
      "--> IMPORTANT: Now, upload 'normalized_questions.parquet' to 'data/2_processed_data/' using the file browser on the left.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup Environment\n",
    "\n",
    "# 1. Clone your public GitHub repository\n",
    "!git clone https://github.com/adfras/psychology-tutor-engine.git\n",
    "\n",
    "# 2. Change the working directory into your project's root\n",
    "%cd psychology-tutor-engine\n",
    "\n",
    "# 3. Install the specific libraries required for the embedding script\n",
    "# This is more robust than relying on a missing requirements.txt\n",
    "!pip install sentence-transformers pandas pyarrow torch\n",
    "\n",
    "print(\"\\n\\n✅ Repository cloned and essential libraries installed.\")\n",
    "print(\"--> IMPORTANT: Now, upload 'normalized_questions.parquet' to 'data/2_processed_data/' using the file browser on the left.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 546940,
     "status": "ok",
     "timestamp": 1750992679576,
     "user": {
      "displayName": "Alan F",
      "userId": "07540241737049634292"
     },
     "user_tz": -480
    },
    "id": "Fc2uIduSMYX8",
    "outputId": "70a71c4a-65d3-4425-ad9f-00bc7b45135a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data file found. Starting embedding computation...\n",
      "2025-06-27 02:42:19.001941: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750992139.021502    1220 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750992139.027508    1220 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-27 02:42:19.046544: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "--- Starting Embedding Computation ---\n",
      "Using device: cuda\n",
      "Loading sentence-transformer model: 'all-MiniLM-L6-v2'...\n",
      "modules.json: 100% 349/349 [00:00<00:00, 2.69MB/s]\n",
      "config_sentence_transformers.json: 100% 116/116 [00:00<00:00, 778kB/s]\n",
      "README.md: 10.5kB [00:00, 39.4MB/s]\n",
      "sentence_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 424kB/s]\n",
      "config.json: 100% 612/612 [00:00<00:00, 5.63MB/s]\n",
      "model.safetensors: 100% 90.9M/90.9M [00:01<00:00, 89.8MB/s]\n",
      "tokenizer_config.json: 100% 350/350 [00:00<00:00, 2.65MB/s]\n",
      "vocab.txt: 232kB [00:00, 11.8MB/s]\n",
      "tokenizer.json: 466kB [00:00, 33.1MB/s]\n",
      "special_tokens_map.json: 100% 112/112 [00:00<00:00, 1.01MB/s]\n",
      "config.json: 100% 190/190 [00:00<00:00, 1.97MB/s]\n",
      "Computing embeddings for 900488 questions... (This may take a while)\n",
      "Batches: 100% 28141/28141 [07:58<00:00, 58.86it/s] \n",
      "Saving new dataframe with embeddings to 'data/2_processed_data/questions_with_embeddings.parquet'...\n",
      "\n",
      "SUCCESS: Embeddings computed and saved.\n",
      "New dataframe shape: (900488, 387)\n",
      "Output file: data/2_processed_data/questions_with_embeddings.parquet\n",
      "\n",
      "\n",
      "✅ SUCCESS! Embeddings computed.\n",
      "--> You can now download 'questions_with_embeddings.parquet' from the 'data/2_processed_data' folder in the file browser.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Run the Script\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Check that the data file was uploaded correctly before running\n",
    "data_file = Path(\"data/2_processed_data/normalized_questions.parquet\")\n",
    "if not data_file.exists():\n",
    "    print(\"❌ ERROR: Data file not found!\")\n",
    "    print(f\"Please make sure you have uploaded 'normalized_questions.parquet' to the '{data_file.parent}' folder.\")\n",
    "else:\n",
    "    print(\"✅ Data file found. Starting embedding computation...\")\n",
    "    # Execute the script from your cloned repository.\n",
    "    # It will use the libraries we just installed and the GPU.\n",
    "    !python src/reasoning_engine/build_rag_index.py\n",
    "\n",
    "    output_file = Path(\"data/2_processed_data/questions_with_embeddings.parquet\")\n",
    "    if output_file.exists():\n",
    "        print(f\"\\n\\n✅ SUCCESS! Embeddings computed.\")\n",
    "        print(f\"--> You can now download '{output_file.name}' from the '{output_file.parent}' folder in the file browser.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 112,
     "status": "ok",
     "timestamp": 1750992128719,
     "user": {
      "displayName": "Alan F",
      "userId": "07540241737049634292"
     },
     "user_tz": -480
    },
    "id": "CPPXnqigQ-xJ",
    "outputId": "74e6d7c9-5ddd-4fb6-846f-c5f8dec27371"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 130M Jun 27 02:42 data/2_processed_data/normalized_questions.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -lh data/2_processed_data/normalized_questions.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 147762,
     "status": "ok",
     "timestamp": 1750925245252,
     "user": {
      "displayName": "Alan F",
      "userId": "07540241737049634292"
     },
     "user_tz": -480
    },
    "id": "3ZnljpOIRLAK",
    "outputId": "64a8707a-5935-4232-b2fb-8f7d48dae95f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-26 08:05:03.910730: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750925103.944661    3021 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750925103.956754    3021 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-26 08:05:03.987927: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "--- Starting Embedding Computation ---\n",
      "Using device: cuda\n",
      "Loading sentence-transformer model: 'all-MiniLM-L6-v2'...\n",
      "modules.json: 100% 349/349 [00:00<00:00, 2.88MB/s]\n",
      "config_sentence_transformers.json: 100% 116/116 [00:00<00:00, 1.02MB/s]\n",
      "README.md: 10.5kB [00:00, 35.5MB/s]\n",
      "sentence_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 412kB/s]\n",
      "config.json: 100% 612/612 [00:00<00:00, 4.21MB/s]\n",
      "model.safetensors: 100% 90.9M/90.9M [00:01<00:00, 68.8MB/s]\n",
      "tokenizer_config.json: 100% 350/350 [00:00<00:00, 2.86MB/s]\n",
      "vocab.txt: 232kB [00:00, 15.1MB/s]\n",
      "tokenizer.json: 466kB [00:00, 34.9MB/s]\n",
      "special_tokens_map.json: 100% 112/112 [00:00<00:00, 881kB/s]\n",
      "config.json: 100% 190/190 [00:00<00:00, 1.51MB/s]\n",
      "Computing embeddings for 274656 questions... (This may take a while)\n",
      "Batches: 100% 8583/8583 [01:46<00:00, 80.63it/s] \n",
      "Saving new dataframe with embeddings to 'data/2_processed_data/questions_with_embeddings.parquet'...\n",
      "\n",
      "SUCCESS: Embeddings computed and saved.\n",
      "New dataframe shape: (274656, 387)\n",
      "Output file: data/2_processed_data/questions_with_embeddings.parquet\n"
     ]
    }
   ],
   "source": [
    "!python src/reasoning_engine/build_rag_index.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8676,
     "status": "ok",
     "timestamp": 1750992786702,
     "user": {
      "displayName": "Alan F",
      "userId": "07540241737049634292"
     },
     "user_tz": -480
    },
    "id": "u032UkgwSRZW",
    "outputId": "49e732e8-14cb-4e20-9e30-b3e4f37ff0dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Validation of questions_with_embeddings.parquet ---\n",
      "\n",
      "[1/5] Checking for file existence...\n",
      "✅ [PASS] File found.\n",
      "\n",
      "[2/5] Checking if file is readable by pandas/pyarrow...\n",
      "✅ [PASS] File is a valid Parquet file and was read successfully.\n",
      "      - Shape of the dataframe: (900488, 387)\n",
      "\n",
      "[3/5] Verifying schema...\n",
      "✅ [PASS] Core columns ('question', 'answer', 'source') are present.\n",
      "✅ [PASS] Found exactly 384 embedding columns (embed_0 to embed_383).\n",
      "\n",
      "[4/5] Checking for null values...\n",
      "✅ [PASS] 'question' column is free of nulls.\n",
      "\n",
      "[5/5] Checking a sample embedding...\n",
      "✅ [PASS] Sample embedding value is a valid number (e.g., 0.1041).\n",
      "\n",
      "==================================================\n",
      "--- VALIDATION SUMMARY ---\n",
      "✅ SUCCESS: The file 'questions_with_embeddings.parquet' is valid.\n",
      "It is safe to download and stop the runtime.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell for validating the output file before download\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "print(\"--- Starting Validation of questions_with_embeddings.parquet ---\")\n",
    "\n",
    "# Define the path to the file we want to test\n",
    "FILE_TO_TEST = Path(\"data/2_processed_data/questions_with_embeddings.parquet\")\n",
    "is_valid = True\n",
    "\n",
    "# 1. Check for File Existence\n",
    "print(f\"\\n[1/5] Checking for file existence...\")\n",
    "if not FILE_TO_TEST.exists():\n",
    "    print(f\"❌ [FAIL] File not found at: {FILE_TO_TEST}\")\n",
    "    is_valid = False\n",
    "else:\n",
    "    print(f\"✅ [PASS] File found.\")\n",
    "\n",
    "# Proceed only if the file exists\n",
    "if is_valid:\n",
    "    try:\n",
    "        # 2. Check if the file is readable (not corrupted)\n",
    "        print(f\"\\n[2/5] Checking if file is readable by pandas/pyarrow...\")\n",
    "        df = pd.read_parquet(FILE_TO_TEST)\n",
    "        print(f\"✅ [PASS] File is a valid Parquet file and was read successfully.\")\n",
    "        print(f\"      - Shape of the dataframe: {df.shape}\")\n",
    "\n",
    "        # 3. Check for correct schema (core columns + embeddings)\n",
    "        print(f\"\\n[3/5] Verifying schema...\")\n",
    "        expected_core_cols = {'question', 'answer', 'source'}\n",
    "        actual_cols = set(df.columns)\n",
    "\n",
    "        if expected_core_cols.issubset(actual_cols):\n",
    "            print(f\"✅ [PASS] Core columns ('question', 'answer', 'source') are present.\")\n",
    "        else:\n",
    "            print(f\"❌ [FAIL] Missing core columns: {expected_core_cols - actual_cols}\")\n",
    "            is_valid = False\n",
    "\n",
    "        embedding_cols = [c for c in df.columns if c.startswith('embed_')]\n",
    "        if len(embedding_cols) == 384:\n",
    "            print(f\"✅ [PASS] Found exactly 384 embedding columns (embed_0 to embed_383).\")\n",
    "        else:\n",
    "            print(f\"❌ [FAIL] Expected 384 embedding columns, but found {len(embedding_cols)}.\")\n",
    "            is_valid = False\n",
    "\n",
    "        # 4. Check for null values in critical columns\n",
    "        print(f\"\\n[4/5] Checking for null values...\")\n",
    "        if df['question'].isnull().any():\n",
    "            print(f\"❌ [FAIL] Null values found in the 'question' column.\")\n",
    "            is_valid = False\n",
    "        else:\n",
    "            print(f\"✅ [PASS] 'question' column is free of nulls.\")\n",
    "\n",
    "        # 5. Check a sample embedding for valid data\n",
    "        print(f\"\\n[5/5] Checking a sample embedding...\")\n",
    "        # Check that the first value of the first embedding column is a valid number\n",
    "        sample_value = df['embed_0'].iloc[0]\n",
    "        if pd.notna(sample_value) and isinstance(sample_value, np.floating):\n",
    "            print(f\"✅ [PASS] Sample embedding value is a valid number (e.g., {sample_value:.4f}).\")\n",
    "        else:\n",
    "            print(f\"❌ [FAIL] Sample embedding value is null or not a number.\")\n",
    "            is_valid = False\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ [FAIL] An error occurred while reading or testing the file: {e}\")\n",
    "        is_valid = False\n",
    "\n",
    "# --- Final Conclusion ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"--- VALIDATION SUMMARY ---\")\n",
    "if is_valid:\n",
    "    print(\"✅ SUCCESS: The file 'questions_with_embeddings.parquet' is valid.\")\n",
    "    print(\"It is safe to download and stop the runtime.\")\n",
    "else:\n",
    "    print(\"❌ FAILURE: The file is invalid or corrupted. DO NOT download it.\")\n",
    "    print(\"Please review the errors above.\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNT4vqXOV3/S67N0mshPfoc",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
