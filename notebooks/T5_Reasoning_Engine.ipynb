{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cw8WuOVwzxGu",
        "outputId": "a5e06a0e-ef69-4066-8781-ec361c272059"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✅ Setup complete. Your Google Drive is mounted and libraries are installed.\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Setup and Environment\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount your Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install required libraries\n",
        "# 'accelerate' is important for efficient training on GPUs\n",
        "!pip install transformers datasets torch accelerate -q\n",
        "\n",
        "print(\"✅ Setup complete. Your Google Drive is mounted and libraries are installed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKNbI_kA1JUC",
        "outputId": "b019a653-d1da-46b6-b777-8942aa6801c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Working Directory: /content\n",
            "Full path being checked for training data: /content/drive/MyDrive/psychology_tutor_engine/data/4_training_sets/distractor_generation_training_data_DOMAIN_AWARE_FIXED.parquet\n",
            "✅ Training data found at: /content/drive/MyDrive/psychology_tutor_engine/data/4_training_sets/distractor_generation_training_data_DOMAIN_AWARE_FIXED.parquet\n",
            "✅ Model output will be saved to: /content/drive/MyDrive/psychology_tutor_engine/models/distractor_generator_t5_domain_aware\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Configuration and Paths (Corrected)\n",
        "import os\n",
        "\n",
        "# --- ⚠️ IMPORTANT: EDIT THIS LINE -------------------------------------------------\n",
        "# Set this to the path of your project folder in Google Drive\n",
        "GDRIVE_PROJECT_PATH = '/content/drive/MyDrive/psychology_tutor_engine'\n",
        "# ----------------------------------------------------------------------------------\n",
        "\n",
        "# --- Define file paths based on your Drive structure ---\n",
        "# This part is correct\n",
        "TRAINING_DATA_FILE = os.path.join(GDRIVE_PROJECT_PATH, 'data/4_training_sets/distractor_generation_training_data_DOMAIN_AWARE_FIXED.parquet')\n",
        "OUTPUT_MODEL_DIR = os.path.join(GDRIVE_PROJECT_PATH, 'models/distractor_generator_t5_domain_aware')\n",
        "\n",
        "# --- ADDED: A quick check to see what the current working directory is ---\n",
        "print(f\"Current Working Directory: {os.getcwd()}\")\n",
        "print(f\"Full path being checked for training data: {TRAINING_DATA_FILE}\")\n",
        "\n",
        "# --- Verify paths and create output directory (with corrected f-strings) ---\n",
        "if not os.path.exists(TRAINING_DATA_FILE):\n",
        "    # This is the corrected line for the error message\n",
        "    raise FileNotFoundError(f\"FATAL: Training data file not found at '{TRAINING_DATA_FILE}'. Please check your GDRIVE_PROJECT_PATH.\")\n",
        "else:\n",
        "    # This is the corrected line for the success message\n",
        "    print(f\"✅ Training data found at: {TRAINING_DATA_FILE}\")\n",
        "\n",
        "os.makedirs(OUTPUT_MODEL_DIR, exist_ok=True)\n",
        "# This is the corrected line for the output message\n",
        "print(f\"✅ Model output will be saved to: {OUTPUT_MODEL_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486,
          "referenced_widgets": [
            "bfa9ecc96d1741229ec6d2d300670e18",
            "bc7948256b5743fdb472876bb0028077",
            "49da184c03274fa6ad02e739e1ca54c2",
            "4dae624ee2e84a5db541eed4a39baa7a",
            "a15d5b6ea67e48fcb6d0810de6ac6b0c",
            "68632f7bb97b454b8a55b23eb669a932",
            "82bb44d9548543408140c2f4e873fb34",
            "b1da0e23d2c84a83a0140fd0dcf1fffe",
            "691df6b286cf46e4a5f2365fee727d77",
            "98d6b9a6d93a494da78fc0f144fa150e",
            "c558a8e0035f4eb8a253452455013185"
          ]
        },
        "id": "w6K3DxnS3DtT",
        "outputId": "3c51fb64-b9ba-41b0-b6c1-18432313a968"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting PRODUCTION Fine-tuning of t5-small ---\n",
            "Loading Parquet file...\n",
            "Data Cleaning: Removed 6 rows with identical answers/distractors.\n",
            "Using 49793 clean examples for training.\n",
            "Added <ANS> and </ANS> special tokens to the tokenizer.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bfa9ecc96d1741229ec6d2d300670e18",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/49793 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting Final Training Run ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1560' max='1560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1560/1560 40:12, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>4.167800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>3.647200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>3.560000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>3.500800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>3.472100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>3.470300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Training Complete ---\n",
            "\n",
            "Saving production model and tokenizer to /content/drive/MyDrive/psychology_tutor_engine/models/distractor_generator_t5_production...\n",
            "✅ Production model saved successfully!\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Final Production Training Script\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorForSeq2Seq,\n",
        ")\n",
        "\n",
        "# --- Configuration ---\n",
        "BASE_MODEL = \"t5-small\"\n",
        "OUTPUT_MODEL_DIR_PROD = os.path.join(GDRIVE_PROJECT_PATH, 'models/distractor_generator_t5_production')\n",
        "\n",
        "print(f\"--- Starting PRODUCTION Fine-tuning of {BASE_MODEL} ---\")\n",
        "\n",
        "# 1. Load the dataset\n",
        "print(\"Loading Parquet file...\")\n",
        "df = pd.read_parquet(TRAINING_DATA_FILE)\n",
        "\n",
        "# 2. Filter the data (as per your recommendation D)\n",
        "initial_rows = len(df)\n",
        "df_clean = df[df[\"correct_answer\"].str.lower() != df[\"distractor\"].str.lower()].copy()\n",
        "print(f\"Data Cleaning: Removed {initial_rows - len(df_clean)} rows with identical answers/distractors.\")\n",
        "train_dataset = Dataset.from_pandas(df_clean)\n",
        "print(f\"Using {len(train_dataset)} clean examples for training.\")\n",
        "\n",
        "# 3. Load Tokenizer and add special tokens (as per your recommendation B)\n",
        "tokenizer = T5Tokenizer.from_pretrained(BASE_MODEL)\n",
        "tokenizer.add_special_tokens({'additional_special_tokens': ['<ANS>', '</ANS>']})\n",
        "print(\"Added <ANS> and </ANS> special tokens to the tokenizer.\")\n",
        "\n",
        "# 4. Load Model and resize embeddings for the new tokens\n",
        "model = T5ForConditionalGeneration.from_pretrained(BASE_MODEL)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# 5. Pre-processing function with the new prompt format\n",
        "def preprocess(examples):\n",
        "    prefix = \"generate distractor: \"\n",
        "    inputs = [f\"{prefix}question: {q} answer: <ANS> {a} </ANS>\" for q, a in zip(examples[\"question\"], examples[\"correct_answer\"])]\n",
        "    model_in = tokenizer(inputs, max_length=512, truncation=True)\n",
        "    labels = tokenizer(text_target=examples[\"distractor\"], max_length=128, truncation=True)\n",
        "    model_in[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_in\n",
        "\n",
        "# 6. Apply preprocessing\n",
        "tokenized_dataset = train_dataset.map(preprocess, batched=True, remove_columns=train_dataset.column_names)\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding=True)\n",
        "\n",
        "# 7. Training Arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_MODEL_DIR_PROD,\n",
        "    num_train_epochs=4,\n",
        "    per_device_train_batch_size=32,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=5e-5,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    logging_steps=250,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    fp16=True,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "# 8. Initialize and run the Trainer\n",
        "trainer = Trainer(model=model, args=training_args, train_dataset=tokenized_dataset, data_collator=data_collator)\n",
        "print(\"\\n--- Starting Final Training Run ---\")\n",
        "trainer.train()\n",
        "print(\"--- Training Complete ---\")\n",
        "\n",
        "# 9. Save the final model\n",
        "print(f\"\\nSaving production model and tokenizer to {OUTPUT_MODEL_DIR_PROD}...\")\n",
        "trainer.save_model(OUTPUT_MODEL_DIR_PROD)\n",
        "tokenizer.save_pretrained(OUTPUT_MODEL_DIR_PROD)\n",
        "print(\"✅ Production model saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcfGz8VcB4uq",
        "outputId": "a94ec1b4-2922-4047-c549-7e49f28ed4d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading production model from: /content/drive/MyDrive/psychology_tutor_engine/models/distractor_generator_t5_production\n",
            "Using device: cuda\n",
            "\n",
            "--- Psychology Example ---\n",
            "Question: How does behaviorism differ from psychoanalytic theory?\n",
            "Correct Answer: behaviorism suggests that behavior is learned through environmental stimuli, while psychoanalytic theory posits that behavior is driven by unconscious desires and conflicts\n",
            "GENERATED DISTRACTOR: Behaviorism is a theory that emphasizes the importance of social interaction, as it emphasize the impact of behaviors on the environment and the emotional environment.\n",
            "\n",
            "--- Logic/Math Example ---\n",
            "Question: Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and sells four to her neighbor. How many eggs does she have left to sell at the market?\n",
            "Correct Answer: 9\n",
            "GENERATED DISTRACTOR: 7\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Testing the Production Model (with Advanced Inference)\n",
        "import torch\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "import random\n",
        "\n",
        "# --- LOAD THE MODEL ---\n",
        "MODEL_PATH = '/content/drive/MyDrive/psychology_tutor_engine/models/distractor_generator_t5_production'\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(f\"Loading production model from: {MODEL_PATH}\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(MODEL_PATH).to(device)\n",
        "tokenizer = T5Tokenizer.from_pretrained(MODEL_PATH)\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "# --- FINAL GENERATION FUNCTION (IMPLEMENTING YOUR RECOMMENDATIONS) ---\n",
        "def generate_distractor(question, correct_answer):\n",
        "    # Recommendation B: Post-process numerics for plausible distractors\n",
        "    if correct_answer.isdigit():\n",
        "        # This simple rule is more reliable than the LLM for numeric distractors\n",
        "        return str(int(correct_answer) + random.choice([-2, -1, 1, 2]))\n",
        "\n",
        "    # If the answer is not purely numeric, use the fine-tuned model\n",
        "    input_text = f\"generate distractor: question: {question} answer: <ANS> {correct_answer} </ANS>\"\n",
        "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n",
        "\n",
        "    # Recommendation A: Block the exact answer tokens at generation time\n",
        "    # This prevents the model from accidentally generating the correct answer\n",
        "    bad_words_ids = [tokenizer(correct_answer, add_special_tokens=False).input_ids]\n",
        "\n",
        "    outputs = model.generate(\n",
        "        input_ids,\n",
        "        max_length=60,\n",
        "        do_sample=True,\n",
        "        top_p=0.9,\n",
        "        temperature=0.7,\n",
        "        no_repeat_ngram_size=2,\n",
        "        bad_words_ids=bad_words_ids  # <-- The extra guardrail\n",
        "    )\n",
        "    distractor = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
        "    return distractor\n",
        "\n",
        "\n",
        "# --- RUN TESTS ---\n",
        "# Example 1: Psychology Question\n",
        "q1 = \"How does behaviorism differ from psychoanalytic theory?\"\n",
        "a1 = \"behaviorism suggests that behavior is learned through environmental stimuli, while psychoanalytic theory posits that behavior is driven by unconscious desires and conflicts\"\n",
        "distractor1 = generate_distractor(q1, a1)\n",
        "\n",
        "print(\"\\n--- Psychology Example ---\")\n",
        "print(f\"Question: {q1}\")\n",
        "print(f\"Correct Answer: {a1}\")\n",
        "print(f\"GENERATED DISTRACTOR: {distractor1}\")\n",
        "\n",
        "# Example 2: Logic/Math Question\n",
        "q2 = \"Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and sells four to her neighbor. How many eggs does she have left to sell at the market?\"\n",
        "a2 = \"9\"\n",
        "distractor2 = generate_distractor(q2, a2)\n",
        "\n",
        "print(\"\\n--- Logic/Math Example ---\")\n",
        "print(f\"Question: {q2}\")\n",
        "print(f\"Correct Answer: {a2}\")\n",
        "print(f\"GENERATED DISTRACTOR: {distractor2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSemb-GHeKY6",
        "outputId": "bba97810-d0c9-46b4-f961-854fe5c694ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Generating Data Integrity Report ---\n",
            "\n",
            "[1/2] Analyzing the source Parquet file...\n",
            "Loaded original file with 49799 rows.\n",
            "\n",
            "  [!] INFO: Found 6 rows (0.01%) where the distractor is identical to the correct answer.\n",
            "  This is expected. These rows are correctly filtered out by the training script.\n",
            "\n",
            "  First 5 duplicates found in source file:\n",
            "                                                question  \\\n",
            "5636   Which of the following extrapyramidal effect i...   \n",
            "8496   Magical thinking is seen in which type of pers...   \n",
            "11798                      Molecular scissors refers to:   \n",
            "17028  A 80 cm long wire is to be cut into two pieces...   \n",
            "43136  A 39-year-old woman presents to the emergency ...   \n",
            "\n",
            "                     correct_answer                    distractor  \\\n",
            "5636         ['Tardive dyskinesia']        ['tardive dyskinesia']   \n",
            "8496                ['schizotypal']               ['Schizotypal']   \n",
            "11798  ['Restriction Endonuclease']  ['Restriction endonuclease']   \n",
            "17028                         ['A']                         ['a']   \n",
            "43136           ['Cholecystectomy']           ['cholecystectomy']   \n",
            "\n",
            "      question_source distractor_source  \n",
            "5636            train             train  \n",
            "8496            train             train  \n",
            "11798           train             train  \n",
            "17028           train             train  \n",
            "43136           train             train  \n",
            "\n",
            "\n",
            "[2/2] Verifying the in-memory data that the model was actually trained on...\n",
            "  - Original rows in source file: 49799\n",
            "  - Rows removed by cleaning process: 6\n",
            "  - Final clean rows used for training: 49793\n",
            "\n",
            "\n",
            "✅ REPORT COMPLETE: The data pipeline is correctly identifying and removing bad data before training.\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: Data Integrity Report\n",
        "import pandas as pd\n",
        "\n",
        "print(\"--- Generating Data Integrity Report ---\")\n",
        "\n",
        "# --- Step 1: Analyze the ORIGINAL source file on disk ---\n",
        "print(\"\\n[1/2] Analyzing the source Parquet file...\")\n",
        "\n",
        "try:\n",
        "    # Load the original dataframe that was used as input for training\n",
        "    df_original = pd.read_parquet(TRAINING_DATA_FILE)\n",
        "    total_original_rows = len(df_original)\n",
        "    print(f\"Loaded original file with {total_original_rows} rows.\")\n",
        "\n",
        "    # Find rows where the distractor is a case-insensitive match for the correct answer\n",
        "    duplicates = df_original[df_original[\"correct_answer\"].str.lower() == df_original[\"distractor\"].str.lower()]\n",
        "    num_dupes = len(duplicates)\n",
        "\n",
        "    if num_dupes > 0:\n",
        "        print(f\"\\n  [!] INFO: Found {num_dupes} rows ({num_dupes/total_original_rows:.2%}) where the distractor is identical to the correct answer.\")\n",
        "        print(\"  This is expected. These rows are correctly filtered out by the training script.\")\n",
        "        print(\"\\n  First 5 duplicates found in source file:\")\n",
        "        print(duplicates.head())\n",
        "    else:\n",
        "        # This is the corrected line with the f-string properly terminated\n",
        "        print(f\"\\n  [✅] INFO: The source file contains 0 duplicate answer/distractor pairs.\")\n",
        "\n",
        "    # --- Step 2: Verify the CLEANED data used in the last training run ---\n",
        "    print(\"\\n\\n[2/2] Verifying the in-memory data that the model was actually trained on...\")\n",
        "\n",
        "    # Re-create the cleaned DataFrame exactly as the training script did\n",
        "    df_cleaned_for_training = df_original[df_original[\"correct_answer\"].str.lower() != df_original[\"distractor\"].str.lower()]\n",
        "    final_training_rows = len(df_cleaned_for_training)\n",
        "\n",
        "    print(f\"  - Original rows in source file: {total_original_rows}\")\n",
        "    print(f\"  - Rows removed by cleaning process: {total_original_rows - final_training_rows}\")\n",
        "    print(f\"  - Final clean rows used for training: {final_training_rows}\")\n",
        "\n",
        "    print(\"\\n\\n✅ REPORT COMPLETE: The data pipeline is correctly identifying and removing bad data before training.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: Could not find the training data file at {TRAINING_DATA_FILE}. Please ensure paths are correct.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "49da184c03274fa6ad02e739e1ca54c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1da0e23d2c84a83a0140fd0dcf1fffe",
            "max": 49793,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_691df6b286cf46e4a5f2365fee727d77",
            "value": 49793
          }
        },
        "4dae624ee2e84a5db541eed4a39baa7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98d6b9a6d93a494da78fc0f144fa150e",
            "placeholder": "​",
            "style": "IPY_MODEL_c558a8e0035f4eb8a253452455013185",
            "value": " 49793/49793 [00:32&lt;00:00, 1587.93 examples/s]"
          }
        },
        "68632f7bb97b454b8a55b23eb669a932": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "691df6b286cf46e4a5f2365fee727d77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82bb44d9548543408140c2f4e873fb34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98d6b9a6d93a494da78fc0f144fa150e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a15d5b6ea67e48fcb6d0810de6ac6b0c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1da0e23d2c84a83a0140fd0dcf1fffe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc7948256b5743fdb472876bb0028077": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68632f7bb97b454b8a55b23eb669a932",
            "placeholder": "​",
            "style": "IPY_MODEL_82bb44d9548543408140c2f4e873fb34",
            "value": "Map: 100%"
          }
        },
        "bfa9ecc96d1741229ec6d2d300670e18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc7948256b5743fdb472876bb0028077",
              "IPY_MODEL_49da184c03274fa6ad02e739e1ca54c2",
              "IPY_MODEL_4dae624ee2e84a5db541eed4a39baa7a"
            ],
            "layout": "IPY_MODEL_a15d5b6ea67e48fcb6d0810de6ac6b0c"
          }
        },
        "c558a8e0035f4eb8a253452455013185": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
